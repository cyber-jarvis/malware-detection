#! /usr/bin/python3

import numpy as np
import pandas as pd
import seaborn as sns
import pickle
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.metrics import classification_report, confusion_matrix
import joblib
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression as lr
from sklearn.ensemble import StackingClassifier

features = ['e_oeminfo',
 'e_ss',
 'e_cparhdr',
 'SizeOfStackReserve',
 'MinorLinkerVersion',
 'SectionAlignment',
 'NumberOfRvaAndSizes',
 'MajorLinkerVersion',
 'LoaderFlags',
 'MinorSubsystemVersion',
 'MinorImageVersion',
 'SizeOfImage',
 'e_ovno',
 'e_cblp',
 'TimeDateStamp',
 'MinorOperatingSystemVersion',
 'SizeOfCode',
 'MajorSubsystemVersion',
 'Magic',
 'NumberOfSymbols',
 'SizeOfHeapCommit',
 'DllCharacteristics',
 'e_oemid',
 'e_cp',
 'e_sp',
 'e_magic',
 'CheckSum',
 'SectionMaxVirtualsize',
 'Subsystem',
 'e_cs',
 'e_ip',
 'SectionsLength',
 'e_maxalloc',
 'e_lfarlc',
 'Machine',
 'AddressOfEntryPoint',
 'PointerToSymbolTable',
 'e_minalloc',
 'Characteristics',
 'FileAlignment',
 'MajorOperatingSystemVersion',
 'SizeOfHeaders',
 'SizeOfOptionalHeader',
 'SizeOfStackCommit',
 'e_crlc',
 'SizeOfInitializedData',
 'SizeOfUninitializedData',
 'ImageBase',
 'SizeOfHeapReserve',
 'NumberOfSections',
 'BaseOfCode',
 'e_lfanew',
 'MajorImageVersion',
 'e_csum']

print("Reading Data ...\n\n")
data = pd.read_csv('./Data/dataset_malwares.csv', sep=',')[features + ['Name', 'Malware']]

X = data.drop(['Name', 'Malware'], axis=1)
y = data['Malware']


#X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.1, random_state=101)
X_train, y_train = X, y

print("Pre-processing ...\n\n")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_new = pd.DataFrame(X_scaled, columns=X.columns)

skpca = PCA(n_components=50)
X_pca = skpca.fit_transform(X_new)
skpca.explained_variance_ratio_.cumsum()[-1]

#--------------------------------------------------------------

print("Training Model ...\n\n")
lr = lr()

estimators = [ 
              ('xg', XGBClassifier(max_depth=20, learning_rate=0.3, n_estimators=100)),
              ('rf', RFC(n_estimators=50, random_state=0, 
                         oob_score = True,
                         max_depth = 24, 
                         max_features = 'sqrt')),
              ('knn', KNeighborsClassifier(n_neighbors = 20, metric = 'minkowski', p = 2))
                 ]
clf_stack = StackingClassifier(estimators, lr)
model_stack = clf_stack.fit(X_pca, y_train)   

#X_test_scaled = scaler.transform(X_test)
#X_test_new = pd.DataFrame(X_test_scaled, columns=X.columns)
#X_test_pca = skpca.transform(X_test_new)

#y_pred = model_stack.predict(X_test_pca)
#score = model_stack.score(X_test_pca,y_test)

#print('Score : ',score)

print("Saving model ...\n\n")
pipe = Pipeline([('scale', scaler),('pca', skpca), ('clf', model_stack)])
joblib.dump(pipe, './models/Stack_model.pkl')
open('./models/Stack_features.pkl', 'wb').write(pickle.dumps(features))

print("End")

#----------------------------------------------------------------------------------------

